"""
Graph Tools for Phase 2-3 Integration
æä¾›å›¾è°±åºåˆ—åŒ–å’Œç‹¬ç«‹è¯„åˆ†åŠŸèƒ½

åŠŸèƒ½ï¼š
1. serialize_graph_to_summary: å°†å›¾æ•°æ®è½¬æ¢ä¸ºç»“æ„åŒ–è‡ªç„¶è¯­è¨€æ‘˜è¦
2. calculate_deterministic_score: åŸºäºå›ºå®šå…¬å¼è®¡ç®—ç¡®å®šæ€§å¾—åˆ†
3. rebuild_graph_from_json: ä» JSON é‡å»º MedicalGraph å¯¹è±¡
"""
from typing import Dict, Any, List, Tuple, Optional
from src.graph.schema import MedicalGraph


def rebuild_graph_from_json(graph_json: Dict[str, Any]) -> MedicalGraph:
    """
    ä» graph_json å­—å…¸é‡å»º MedicalGraph å¯¹è±¡
    
    è¿™æ˜¯ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œç”¨äºåœ¨ workflow ä¸­ä»åºåˆ—åŒ–çŠ¶æ€é‡å»ºå›¾è°±å¯¹è±¡ï¼Œ
    è€Œä¸ä¿®æ”¹ MedicalGraph ç±»å®šä¹‰ (éµå¾ª No-Go Zone çº¦æŸ)ã€‚
    
    Args:
        graph_json: Phase 2 è¾“å‡ºçš„ graph_json å­—å…¸
    
    Returns:
        é‡å»ºçš„ MedicalGraph å®ä¾‹
    """
    graph = MedicalGraph()
    
    # æ¢å¤å…ƒæ•°æ®
    case_metadata = graph_json.get("case_metadata", {})
    graph.meta["raw_text"] = case_metadata.get("raw_text", "")
    graph.meta["case_id"] = case_metadata.get("case_id", "")
    
    phase1_context = graph_json.get("phase1_context", {})
    graph.meta["initial_candidates"] = phase1_context.get("initial_candidates", [])
    graph.meta["initial_reasoning"] = phase1_context.get("initial_reasoning", "")
    
    # è·å–èŠ‚ç‚¹å’Œè¾¹æ•°æ®
    nodes = graph_json.get("graph", {}).get("nodes", {})
    edges = graph_json.get("graph", {}).get("edges", {})
    
    p_nodes = nodes.get("p_nodes", [])
    k_nodes = nodes.get("k_nodes", [])
    d_nodes = nodes.get("d_nodes", [])
    p_k_links = edges.get("p_k_links", [])
    k_d_links = edges.get("k_d_links", [])
    
    # é‡å»º P-Nodes
    for p_data in p_nodes:
        p_id = p_data.get("id")
        if p_id:
            graph.graph.add_node(
                p_id,
                type="P",
                content=p_data.get("content", ""),
                original_text=p_data.get("original_text", ""),
                status=p_data.get("status", "Present"),
                source=p_data.get("source", "Unknown")
            )
    
    # é‡å»º K-Nodes
    for k_data in k_nodes:
        k_id = k_data.get("id")
        if k_id:
            graph.graph.add_node(
                k_id,
                type="K",
                content=k_data.get("content", ""),
                k_type=k_data.get("k_type", "General"),
                source=k_data.get("source", "Unknown"),
                importance=k_data.get("importance", "Common")
            )
    
    # é‡å»º D-Nodes
    for d_data in d_nodes:
        d_id = d_data.get("id")
        if d_id:
            graph.graph.add_node(
                d_id,
                type="D",
                name=d_data.get("name", ""),
                original_id=d_data.get("original_id", ""),
                initial_rank=d_data.get("initial_rank", 999),
                risk_level=d_data.get("risk_level"),
                state=d_data.get("state", "Active")
            )
    
    # é‡å»º P-K è¾¹
    for pk_link in p_k_links:
        source = pk_link.get("source")
        target = pk_link.get("target")
        relation = pk_link.get("relation", "")
        if source and target:
            graph.graph.add_edge(source, target, relation=relation)
    
    # é‡å»º K-D è¾¹
    for kd_link in k_d_links:
        source = kd_link.get("source")
        target = kd_link.get("target")
        relation = kd_link.get("relation", "Support")
        strength = kd_link.get("strength", "Weak")
        if source and target:
            graph.graph.add_edge(source, target, relation=relation, strength=strength)
    
    return graph


def serialize_graph_to_summary(graph: MedicalGraph) -> str:
    """
    å°†å›¾æ•°æ®è½¬æ¢ä¸ºç»“æ„åŒ–çš„è‡ªç„¶è¯­è¨€æ‘˜è¦ï¼ŒæŒ‰ Candidate åˆ†ç»„
    
    æ ¼å¼ç¤ºä¾‹ï¼š
    ```
    Candidate: Pulmonary Embolism (d_25) [Rank: 1]
    - Supporting Evidence: Acute Chest Pain (Match), Shortness of Breath (Match)
    - Conflicting Evidence: No history of DVT (Conflict)
    - Missing Critical Features: D-dimer elevated (Shadow)
    - Knowledge Sources: 3 General K-Nodes, 2 Pivot K-Nodes
    - Naive Score: 2.5
    ```
    
    Args:
        graph: MedicalGraph å®ä¾‹
    
    Returns:
        ç»“æ„åŒ–çš„è‡ªç„¶è¯­è¨€æ‘˜è¦æ–‡æœ¬
    """
    lines = []
    lines.append("=" * 60)
    lines.append("EVIDENCE SUMMARY BY CANDIDATE")
    lines.append("=" * 60)
    lines.append("")
    
    # è·å–æ‰€æœ‰ D-Nodesï¼ŒæŒ‰ initial_rank æ’åº
    d_nodes = graph.get_d_nodes()
    d_nodes_sorted = sorted(d_nodes, key=lambda d: d.get("initial_rank", 999))
    
    # æ„å»º K-Node æŸ¥æ‰¾ç´¢å¼•
    k_nodes = graph.get_k_nodes()
    k_node_map = {k["id"]: k for k in k_nodes}
    
    # æ„å»º P-Node æŸ¥æ‰¾ç´¢å¼•
    p_nodes = graph.get_p_nodes()
    p_node_map = {p["id"]: p for p in p_nodes}
    
    # æ”¶é›†è¾¹ä¿¡æ¯
    p_k_edges = []  # (p_id, k_id, relation)
    k_d_edges = []  # (k_id, d_id, relation, strength)
    
    for source, target, data in graph.graph.edges(data=True):
        source_data = graph.graph.nodes.get(source, {})
        target_data = graph.graph.nodes.get(target, {})
        
        if source_data.get("type") == "P" and target_data.get("type") == "K":
            p_k_edges.append((source, target, data.get("relation", "")))
        elif source_data.get("type") == "K" and target_data.get("type") == "D":
            k_d_edges.append((source, target, data.get("relation", ""), data.get("strength", "")))
    
    # ä¸ºæ¯ä¸ª D-Node ç”Ÿæˆæ‘˜è¦
    for d_node in d_nodes_sorted:
        d_id = d_node["id"]
        d_name = d_node.get("name", "Unknown")
        d_rank = d_node.get("initial_rank", "?")
        d_state = d_node.get("state", "Active")
        
        # çŠ¶æ€æ ‡è®°
        state_marker = "ğŸ”´ PRUNED" if d_state == "Pruned" else ""
        
        lines.append(f"### Candidate: {d_name} ({d_id}) [Rank: {d_rank}] {state_marker}")
        lines.append("")
        
        # æ”¶é›†ä¸è¯¥ D-Node å…³è”çš„ K-Nodes
        related_k_ids = [k_id for k_id, d_id_target, _, _ in k_d_edges if d_id_target == d_id]
        
        # åˆ†ç±»è¯æ®
        supporting = []      # Match çš„ K-Nodes
        conflicting = []     # Conflict çš„ K-Nodes
        missing = []         # Void (Shadow) çš„ K-Nodes
        
        general_k_count = 0
        pivot_k_count = 0
        
        for k_id in related_k_ids:
            k_node = k_node_map.get(k_id, {})
            k_content = k_node.get("content", "Unknown")
            k_type = k_node.get("k_type", "General")
            k_importance = k_node.get("importance", "Common")
            
            # ç»Ÿè®¡ K-Node ç±»å‹
            if k_type == "General":
                general_k_count += 1
            else:
                pivot_k_count += 1
            
            # æŸ¥æ‰¾ P-K å…³ç³»
            pk_relation = "Unknown"
            p_content = ""
            for p_id, k_id_target, relation in p_k_edges:
                if k_id_target == k_id:
                    pk_relation = relation
                    p_node = p_node_map.get(p_id, {})
                    p_content = p_node.get("content", "")
                    break
            
            # æ„å»ºè¯æ®æè¿°
            importance_marker = f"[{k_importance}]" if k_importance in ["Essential", "Pathognomonic"] else ""
            evidence_desc = f"{k_content} {importance_marker}".strip()
            
            if pk_relation == "Match":
                supporting.append(evidence_desc)
            elif pk_relation == "Conflict":
                conflicting.append(evidence_desc)
            elif pk_relation == "Void":
                missing.append(evidence_desc)
        
        # è¾“å‡ºè¯æ®åˆ†ç±»
        if supporting:
            lines.append(f"**âœ… Supporting Evidence ({len(supporting)}):**")
            for ev in supporting[:10]:  # æœ€å¤šæ˜¾ç¤º 10 ä¸ª
                lines.append(f"  - {ev}")
            if len(supporting) > 10:
                lines.append(f"  - ... and {len(supporting) - 10} more")
            lines.append("")
        
        if conflicting:
            lines.append(f"**âŒ Conflicting Evidence ({len(conflicting)}):**")
            for ev in conflicting[:10]:
                lines.append(f"  - {ev}")
            if len(conflicting) > 10:
                lines.append(f"  - ... and {len(conflicting) - 10} more")
            lines.append("")
        
        if missing:
            lines.append(f"**â“ Missing/Shadow Evidence ({len(missing)}):**")
            for ev in missing[:10]:
                lines.append(f"  - {ev}")
            if len(missing) > 10:
                lines.append(f"  - ... and {len(missing) - 10} more")
            lines.append("")
        
        # ç»Ÿè®¡ä¿¡æ¯
        lines.append(f"**ğŸ“Š Statistics:**")
        lines.append(f"  - Knowledge Sources: {general_k_count} General, {pivot_k_count} Pivot")
        lines.append(f"  - Evidence Counts: {len(supporting)} Match, {len(conflicting)} Conflict, {len(missing)} Shadow")
        lines.append("")
        lines.append("-" * 40)
        lines.append("")
    
    return "\n".join(lines)


def calculate_deterministic_score(graph: MedicalGraph) -> Dict[str, float]:
    """
    åŸºäºå›ºå®šå…¬å¼è®¡ç®—æ¯ä¸ª Candidate çš„å¾—åˆ†ï¼ˆä¸ä¾èµ– LLMï¼‰
    
    å…¬å¼ï¼šScore = (Match_Count * 1.0) - (Conflict_Count * 1.5) - (Shadow_Count * 0.1)
    
    æ­¤åˆ†æ•°ä»…ç”¨äºè°ƒè¯•è¾“å‡ºï¼Œå¸®åŠ©åˆ¤æ–­ Phase 2 å»ºå›¾æœ¬èº«çš„è´¨é‡ã€‚
    
    Args:
        graph: MedicalGraph å®ä¾‹
    
    Returns:
        å­—å…¸ï¼š{d_id: score}
    """
    scores = {}
    
    # è·å–æ‰€æœ‰ D-Nodes
    d_nodes = graph.get_d_nodes()
    
    # æ”¶é›†è¾¹ä¿¡æ¯
    p_k_edges = {}  # k_id -> (p_id, relation)
    k_d_edges = {}  # d_id -> [k_id, ...]
    
    for source, target, data in graph.graph.edges(data=True):
        source_data = graph.graph.nodes.get(source, {})
        target_data = graph.graph.nodes.get(target, {})
        
        if source_data.get("type") == "P" and target_data.get("type") == "K":
            # P -> K è¾¹
            if target not in p_k_edges:
                p_k_edges[target] = []
            p_k_edges[target].append((source, data.get("relation", "")))
        elif source_data.get("type") == "K" and target_data.get("type") == "D":
            # K -> D è¾¹
            if target not in k_d_edges:
                k_d_edges[target] = []
            k_d_edges[target].append(source)
    
    # è®¡ç®—æ¯ä¸ª D-Node çš„åˆ†æ•°
    for d_node in d_nodes:
        d_id = d_node["id"]
        
        match_count = 0
        conflict_count = 0
        shadow_count = 0
        
        # è·å–å…³è”çš„ K-Nodes
        related_k_ids = k_d_edges.get(d_id, [])
        
        for k_id in related_k_ids:
            # æŸ¥æ‰¾ P-K å…³ç³»
            pk_relations = p_k_edges.get(k_id, [])
            for _, relation in pk_relations:
                if relation == "Match":
                    match_count += 1
                elif relation == "Conflict":
                    conflict_count += 1
                elif relation == "Void":
                    shadow_count += 1
        
        # åº”ç”¨å…¬å¼
        score = (match_count * 1.0) - (conflict_count * 1.5) - (shadow_count * 0.1)
        scores[d_id] = round(score, 2)
    
    return scores


def get_evidence_breakdown(graph: MedicalGraph, d_id: str) -> Dict[str, Any]:
    """
    è·å–æŒ‡å®š D-Node çš„è¯æ®åˆ†è§£è¯¦æƒ…
    
    Args:
        graph: MedicalGraph å®ä¾‹
        d_id: D-Node ID
    
    Returns:
        è¯æ®åˆ†è§£å­—å…¸
    """
    result = {
        "match_count": 0,
        "conflict_count": 0,
        "shadow_count": 0,
        "match_evidence": [],
        "conflict_evidence": [],
        "shadow_evidence": []
    }
    
    # è·å–ä¸è¯¥ D-Node å…³è”çš„ K-Nodes
    k_nodes_with_edges = graph.get_k_nodes_for_d(d_id)
    
    for k_node, kd_edge in k_nodes_with_edges:
        k_id = k_node["id"]
        k_content = k_node.get("content", "")
        
        # è·å– P-K å…³ç³»
        p_nodes_with_edges = graph.get_p_nodes_for_k(k_id)
        
        for p_node, pk_edge in p_nodes_with_edges:
            relation = pk_edge.get("relation", "")
            p_content = p_node.get("content", "")
            
            evidence_item = {
                "k_content": k_content,
                "p_content": p_content,
                "importance": k_node.get("importance", "Common")
            }
            
            if relation == "Match":
                result["match_count"] += 1
                result["match_evidence"].append(evidence_item)
            elif relation == "Conflict":
                result["conflict_count"] += 1
                result["conflict_evidence"].append(evidence_item)
            elif relation == "Void":
                result["shadow_count"] += 1
                result["shadow_evidence"].append(evidence_item)
    
    return result


def summarize_graph_for_critique(
    graph_json: Dict[str, Any], 
    ground_truth_id: str
) -> str:
    """
    ç”Ÿæˆé¢å‘ Critical Model (Teacher) çš„å›¾è°±æ‘˜è¦
    
    ä¸é€šç”¨ Summary ä¸åŒï¼Œæ­¤å‡½æ•°ä¸“æ³¨äº"çº é”™"åœºæ™¯ï¼Œçªå‡ºä»¥ä¸‹ä¿¡æ¯ï¼š
    1. Missing Evidence: Shadow Nodes (Void å…³ç³»)ï¼Œå°¤å…¶æ˜¯ Essential/Pivot çº§åˆ«
    2. Conflicts: ä¸è¯Šæ–­å†²çªçš„è¯æ®
    3. Support Strength: åŒºåˆ† Strong/Weak æ”¯æŒ
    4. Ground Truth ç›¸å…³æ€§: ç‰¹åˆ«æ ‡æ³¨ä¸æ­£ç¡®ç­”æ¡ˆç›¸å…³çš„è¯æ®
    
    Args:
        graph_json: Phase 2 è¾“å‡ºçš„å›¾è°± JSON (MedicalGraph.to_dict() çš„è¾“å‡º)
        ground_truth_id: æ­£ç¡®ç­”æ¡ˆçš„ç–¾ç—… ID (ä¸å¸¦ d_ å‰ç¼€)
    
    Returns:
        ç»“æ„åŒ–çš„è‡ªç„¶è¯­è¨€æ‘˜è¦ï¼Œä¾› Teacher åˆ†æé”™è¯¯åŸå› 
    """
    from collections import defaultdict
    
    lines = []
    lines.append("=" * 60)
    lines.append("DIAGNOSTIC REASONING ANALYSIS (For Teacher Review)")
    lines.append("=" * 60)
    
    graph_data = graph_json.get("graph", {})
    nodes = graph_data.get("nodes", {})
    edges = graph_data.get("edges", {})
    
    # æ„å»ºç´¢å¼•
    k_node_map = {k["id"]: k for k in nodes.get("k_nodes", [])}
    p_node_map = {p["id"]: p for p in nodes.get("p_nodes", [])}
    d_node_map = {d["id"]: d for d in nodes.get("d_nodes", [])}
    
    # æ”¶é›†è¾¹ä¿¡æ¯
    pk_by_k = defaultdict(list)  # k_id -> [(p_id, relation), ...]
    kd_by_d = defaultdict(list)  # d_id -> [(k_id, relation, strength), ...]
    
    for edge in edges.get("p_k_links", []):
        pk_by_k[edge.get("target", "")].append(
            (edge.get("source", ""), edge.get("relation", ""))
        )
    
    for edge in edges.get("k_d_links", []):
        kd_by_d[edge.get("target", "")].append(
            (edge.get("source", ""), edge.get("relation", ""), edge.get("strength", ""))
        )
    
    # === Section 1: Missing Evidence (Shadow Nodes / Void Relations) ===
    lines.append("\n### ğŸ” MISSING EVIDENCE (Shadow Nodes / Void Relations)")
    lines.append("These are clinical features the agent could not find in the patient narrative:")
    
    shadow_count = 0
    for k_id, pk_list in pk_by_k.items():
        for p_id, relation in pk_list:
            if relation == "Void":
                k_node = k_node_map.get(k_id, {})
                k_content = k_node.get("content", k_id)
                importance = k_node.get("importance", "Common")
                k_type = k_node.get("k_type", "General")
                
                # æ ‡è®°å…³é”®ç¼ºå¤±
                marker = ""
                if importance in ["Essential", "Pathognomonic"]:
                    marker = "âš ï¸ CRITICAL"
                elif k_type == "Pivot":
                    marker = "ğŸ“Œ PIVOT"
                
                lines.append(f"  - {k_content} [{importance}, {k_type}] {marker}")
                shadow_count += 1
    
    if shadow_count == 0:
        lines.append("  (No shadow nodes found - all features were matched)")
    else:
        lines.append(f"\n  Total Shadow Nodes: {shadow_count}")
    
    # === Section 2: Conflicting Evidence ===
    lines.append("\n### âŒ CONFLICTING EVIDENCE")
    lines.append("These are features where patient status contradicts expected findings:")
    
    conflict_count = 0
    for k_id, pk_list in pk_by_k.items():
        for p_id, relation in pk_list:
            if relation == "Conflict":
                k_node = k_node_map.get(k_id, {})
                p_node = p_node_map.get(p_id, {})
                
                k_content = k_node.get("content", k_id)
                p_content = p_node.get("content", p_id)
                p_status = p_node.get("status", "Unknown")
                
                lines.append(
                    f"  - K-Node: '{k_content}' "
                    f"<-- P-Node: '{p_content}' (Status: {p_status})"
                )
                conflict_count += 1
    
    if conflict_count == 0:
        lines.append("  (No conflicts found)")
    else:
        lines.append(f"\n  Total Conflicts: {conflict_count}")
    
    # === Section 3: Ground Truth Analysis ===
    # ç¡®ä¿æ ¼å¼æ­£ç¡®
    gt_d_id = f"d_{ground_truth_id}" if not ground_truth_id.startswith("d_") else ground_truth_id
    gt_name = d_node_map.get(gt_d_id, {}).get("name", "Unknown")
    
    lines.append(f"\n### ğŸ¯ GROUND TRUTH ANALYSIS: {gt_name} ({gt_d_id})")
    
    gt_evidence = kd_by_d.get(gt_d_id, [])
    if gt_evidence:
        lines.append(f"  Evidence supporting the CORRECT diagnosis:")
        
        support_list = []
        rule_out_list = []
        
        for k_id, relation, strength in gt_evidence:
            k_node = k_node_map.get(k_id, {})
            k_content = k_node.get("content", k_id)
            importance = k_node.get("importance", "Common")
            
            # æ£€æŸ¥è¯¥ K-Node çš„ P-K å…³ç³»
            pk_relations = pk_by_k.get(k_id, [])
            pk_summary = []
            for p_id, pk_rel in pk_relations:
                pk_summary.append(pk_rel)
            pk_str = ", ".join(set(pk_summary)) if pk_summary else "No P-K links"
            
            if relation == "Support":
                support_list.append(f"    âœ“ {k_content} [{strength}] (P-K: {pk_str})")
            elif relation == "Rule_Out":
                rule_out_list.append(f"    âœ— {k_content} [{strength}] (P-K: {pk_str})")
        
        if support_list:
            lines.append("  **Supporting K-Nodes:**")
            lines.extend(support_list[:10])  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
        
        if rule_out_list:
            lines.append("  **Rule-Out K-Nodes:**")
            lines.extend(rule_out_list[:5])
        
        # è®¡ç®—æ”¯æŒå¼ºåº¦
        essential_support = sum(
            1 for k_id, rel, _ in gt_evidence 
            if rel == "Support" and k_node_map.get(k_id, {}).get("importance") in ["Essential", "Pathognomonic"]
        )
        lines.append(f"\n  Essential/Pathognomonic Support Count: {essential_support}")
        
    else:
        lines.append("  âš ï¸ NO EVIDENCE found supporting the correct diagnosis!")
        lines.append("  This suggests the agent completely missed key features for this condition.")
    
    # === Section 4: All Candidates Summary ===
    lines.append("\n### ğŸ“Š ALL CANDIDATES EVIDENCE SUMMARY")
    
    for d_node in nodes.get("d_nodes", []):
        d_id = d_node["id"]
        d_name = d_node.get("name", "Unknown")
        d_rank = d_node.get("initial_rank", "?")
        
        evidence = kd_by_d.get(d_id, [])
        
        support_count = sum(1 for _, rel, _ in evidence if rel == "Support")
        rule_out_count = sum(1 for _, rel, _ in evidence if rel == "Rule_Out")
        
        # è®¡ç®— Match/Conflict/Void ç»Ÿè®¡
        match_count = 0
        conflict_count = 0
        void_count = 0
        
        for k_id, _, _ in evidence:
            for p_id, pk_rel in pk_by_k.get(k_id, []):
                if pk_rel == "Match":
                    match_count += 1
                elif pk_rel == "Conflict":
                    conflict_count += 1
                elif pk_rel == "Void":
                    void_count += 1
        
        # æ ‡è®° Ground Truth
        marker = " â† GROUND TRUTH" if d_id == gt_d_id else ""
        
        lines.append(
            f"  - {d_name} ({d_id}) [Rank: {d_rank}]{marker}"
        )
        lines.append(
            f"    K-D: {support_count} Support, {rule_out_count} Rule_Out | "
            f"P-K: {match_count} Match, {conflict_count} Conflict, {void_count} Void"
        )
    
    # === Section 5: Patient Features Summary ===
    lines.append("\n### ğŸ‘¤ PATIENT FEATURES (P-Nodes)")
    
    present_features = []
    absent_features = []
    
    for p_node in nodes.get("p_nodes", []):
        content = p_node.get("content", "")
        status = p_node.get("status", "Present")
        
        if status == "Present":
            present_features.append(content)
        elif status == "Absent":
            absent_features.append(content)
    
    if present_features:
        lines.append(f"  **Present ({len(present_features)}):** " + ", ".join(present_features[:15]))
        if len(present_features) > 15:
            lines.append(f"    ... and {len(present_features) - 15} more")
    
    if absent_features:
        lines.append(f"  **Absent ({len(absent_features)}):** " + ", ".join(absent_features[:10]))
        if len(absent_features) > 10:
            lines.append(f"    ... and {len(absent_features) - 10} more")
    
    lines.append("\n" + "=" * 60)
    
    return "\n".join(lines)


def build_prompt_with_hint(base_prompt: str, global_hint: Optional[str]) -> str:
    """
    å°† Teacher Hint é™„åŠ åˆ° Prompt æœ«å°¾
    
    ç”¨äº Offline Training çš„é‡è¯•æµç¨‹ï¼Œå°† Critical Model çš„åé¦ˆ
    æ³¨å…¥åˆ°å„ Phase çš„ System Prompt ä¸­ã€‚
    
    Args:
        base_prompt: åŸå§‹ System Prompt
        global_hint: Teacher çš„åé¦ˆæ–‡æœ¬ï¼ˆå¯èƒ½ä¸º None æˆ–ç©ºï¼‰
    
    Returns:
        é™„åŠ äº† Hint çš„ Prompt
    """
    if global_hint and global_hint.strip():
        return base_prompt + f"\n\n[TEACHER FEEDBACK - IMPORTANT]:\n{global_hint}"
    return base_prompt


# ==================== åˆ«åå‡½æ•° (å…¼å®¹ Online Inference) ====================

def summarize_graph_for_judge(
    graph_json: Dict[str, Any], 
    naive_scores: Optional[Dict[str, float]] = None
) -> str:
    """
    ä¸º Phase 3 Judge ç”Ÿæˆ Rich Structured Summary
    
    è¿™æ˜¯é‡æ„åçš„æ ¸å¿ƒæ‘˜è¦å‡½æ•°ï¼Œç”¨äºæ›¿ä»£åŸå§‹ JSON è¾“å…¥ã€‚
    æ ¼å¼éµå¾ª PHASE3_REFACTOR_PLAN.md çš„è®¾è®¡ã€‚
    
    è®¾è®¡ç›®æ ‡ï¼š
    - é«˜ä¿¡æ¯å¯†åº¦ï¼Œæ›¿ä»£åŸå§‹ JSON
    - ç¦æ­¢æ›´æ”¹åŒ»å­¦å®ä½“å†…å®¹ï¼Œä»…æ”¹å˜å‘ˆç°å½¢å¼
    - Shadow åªåˆ—å‡º Pathognomonic ç±»å‹çš„ç¼ºå¤±ç‰¹å¾
    
    Args:
        graph_json: Phase 2 è¾“å‡ºçš„ graph_json å­—å…¸
        naive_scores: é¢„è®¡ç®—çš„æœ´ç´ è¯„åˆ†å­—å…¸ {d_id: score}ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        Rich Structured Summary æ–‡æœ¬
    """
    from collections import defaultdict
    
    # æå–èŠ‚ç‚¹å’Œè¾¹
    graph_data = graph_json.get("graph", {})
    nodes = graph_data.get("nodes", {})
    edges = graph_data.get("edges", {})
    
    p_nodes = nodes.get("p_nodes", [])
    k_nodes = nodes.get("k_nodes", [])
    d_nodes = nodes.get("d_nodes", [])
    p_k_links = edges.get("p_k_links", [])
    k_d_links = edges.get("k_d_links", [])
    
    # æ„å»ºç´¢å¼•
    p_node_map = {p["id"]: p for p in p_nodes}
    k_node_map = {k["id"]: k for k in k_nodes}
    d_node_map = {d["id"]: d for d in d_nodes}
    
    # æ„å»º K-Node -> P-K å…³ç³»æ˜ å°„
    pk_by_k = defaultdict(list)  # k_id -> [(p_id, relation), ...]
    for edge in p_k_links:
        k_id = edge.get("target", "")
        p_id = edge.get("source", "")
        relation = edge.get("relation", "")
        pk_by_k[k_id].append((p_id, relation))
    
    # æ„å»º D-Node -> K-Nodes æ˜ å°„
    kd_by_d = defaultdict(list)  # d_id -> [k_id, ...]
    for edge in k_d_links:
        d_id = edge.get("target", "")
        k_id = edge.get("source", "")
        kd_by_d[d_id].append(k_id)
    
    # å¦‚æœæ²¡æœ‰ä¼ å…¥ naive_scoresï¼Œè‡ªåŠ¨è®¡ç®—
    if naive_scores is None:
        graph = rebuild_graph_from_json(graph_json)
        naive_scores = calculate_deterministic_score(graph)
    
    # æŒ‰ initial_rank æ’åº D-Nodes
    d_nodes_sorted = sorted(d_nodes, key=lambda d: d.get("initial_rank", 999))
    
    lines = []
    lines.append("=" * 60)
    lines.append("RICH STRUCTURED SUMMARY (Phase 3 Evidence)")
    lines.append("=" * 60)
    lines.append("")
    
    for d_node in d_nodes_sorted:
        d_id = d_node.get("id", "")
        d_name = d_node.get("name", "Unknown")
        d_rank = d_node.get("initial_rank", "?")
        d_state = d_node.get("state", "Active")
        
        # è·å– Naive Score
        score = naive_scores.get(d_id, 0.0)
        score_str = f"+{score:.1f}" if score >= 0 else f"{score:.1f}"
        
        # çŠ¶æ€æ ‡è®°
        state_marker = " ğŸ”´ PRUNED" if d_state == "Pruned" else ""
        
        # Header
        lines.append(f"### [{d_name}] (ID: {d_id}) â€“ Naive Score: **{score_str}**{state_marker}")
        lines.append(f"    Phase 1 Rank: {d_rank}")
        lines.append("")
        
        # æ”¶é›†è¯æ®
        match_evidence = []
        conflict_evidence = []
        shadow_pathognomonic = []  # åªæ”¶é›† Pathognomonic ç±»å‹
        has_pivot_match = False
        
        related_k_ids = kd_by_d.get(d_id, [])
        
        for k_id in related_k_ids:
            k_node = k_node_map.get(k_id, {})
            k_content = k_node.get("content", k_id)
            k_importance = k_node.get("importance", "Weak")
            k_type = k_node.get("k_type", "General")
            
            # è·å– P-K å…³ç³»
            pk_relations = pk_by_k.get(k_id, [])
            
            for p_id, relation in pk_relations:
                p_node = p_node_map.get(p_id, {})
                p_content = p_node.get("content", p_id)
                p_status = p_node.get("status", "Present")
                
                # æ„å»ºè¯æ®æè¿°
                importance_tag = f"[{k_importance}]" if k_importance in ["Essential", "Pathognomonic", "Strong"] else ""
                pivot_tag = " [PIVOT]" if k_type == "Pivot" else ""
                
                if relation == "Match":
                    match_evidence.append(f'{p_content} â†” "{k_content}" {importance_tag}{pivot_tag}')
                    # æ£€æŸ¥ Pivot Match
                    if k_type == "Pivot":
                        has_pivot_match = True
                        
                elif relation == "Conflict":
                    conflict_evidence.append(f'{p_content} (Status: {p_status}) âœ— "{k_content}" {importance_tag}')
                    
                elif relation == "Void":
                    # **å…³é”®é€»è¾‘**: åªæ”¶é›† Pathognomonic ç±»å‹çš„ Shadow
                    if k_importance == "Pathognomonic":
                        shadow_pathognomonic.append(f'"{k_content}" [Pathognomonic] - MISSING')
        
        # è¾“å‡º Evidence Sections
        # [+] MATCH
        if match_evidence:
            lines.append(f"â€¢ **[+] MATCH ({len(match_evidence)}):**")
            for ev in match_evidence[:8]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                lines.append(f"    - {ev}")
            if len(match_evidence) > 8:
                lines.append(f"    - ... and {len(match_evidence) - 8} more")
        else:
            lines.append("â€¢ **[+] MATCH (0):** None")
        lines.append("")
        
        # [-] CONFLICT
        if conflict_evidence:
            lines.append(f"â€¢ **[-] CONFLICT ({len(conflict_evidence)}):**")
            for ev in conflict_evidence[:5]:
                lines.append(f"    - {ev}")
            if len(conflict_evidence) > 5:
                lines.append(f"    - ... and {len(conflict_evidence) - 5} more")
        else:
            lines.append("â€¢ **[-] CONFLICT (0):** None")
        lines.append("")
        
        # [?] CRITICAL MISSING (Shadow - Pathognomonic Only)
        if shadow_pathognomonic:
            lines.append(f"â€¢ **[?] CRITICAL MISSING ({len(shadow_pathognomonic)} Pathognomonic):**")
            for ev in shadow_pathognomonic[:5]:
                lines.append(f"    - {ev}")
            if len(shadow_pathognomonic) > 5:
                lines.append(f"    - ... and {len(shadow_pathognomonic) - 5} more")
        else:
            lines.append("â€¢ **[?] CRITICAL MISSING:** None (No Pathognomonic features missing)")
        lines.append("")
        
        # Pivot Status
        pivot_status = "âœ… YES (Pivot Feature Matched)" if has_pivot_match else "âŒ NO"
        lines.append(f"â€¢ **Pivot Status:** {pivot_status}")
        lines.append("")
        lines.append("-" * 50)
        lines.append("")
    
    return "\n".join(lines)


def calculate_naive_scores(graph_json: Dict[str, Any]) -> Dict[str, float]:
    """
    è®¡ç®—æœ´ç´ è¯„åˆ†
    
    è¿™æ˜¯ calculate_deterministic_score çš„åˆ«åï¼Œæ¥å— graph_json å­—å…¸è¾“å…¥ã€‚
    
    Args:
        graph_json: Phase 2 è¾“å‡ºçš„ graph_json å­—å…¸
    
    Returns:
        å­—å…¸ï¼š{d_id: score}
    """
    graph = rebuild_graph_from_json(graph_json)
    return calculate_deterministic_score(graph)






