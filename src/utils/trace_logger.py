"""
Trace Logger for System Diagnostics
é€æ˜åŒ–è°ƒè¯•æ—¥å¿—å·¥å…·ï¼Œæ”¯æŒäººå·¥è‚‰çœ¼æ£€æŸ¥ (Human Audit)

è®¾è®¡åŸåˆ™ï¼š
- å•ä¾‹æ¨¡å¼ (Singleton)ï¼šå…¨å±€å¯è®¿é—®ï¼Œæ— éœ€å±‚å±‚ä¼ é€’
- éä¾µå…¥æ€§ï¼šä¸ä¿®æ”¹ç°æœ‰å‡½æ•°ç­¾å
- ç»“æ„åŒ–è¾“å‡ºï¼šMarkdown æ ¼å¼ï¼Œä¾¿äºäººç±»å¿«é€Ÿé˜…è¯»
"""
import os
import threading
from datetime import datetime
from typing import Dict, Any, List, Optional


class TraceLogger:
    """
    å•ä¾‹æ¨¡å¼çš„è¿½è¸ªæ—¥å¿—å™¨
    
    è®°å½•å†…å®¹ï¼š
    - Phase 1: Top-5 Candidates
    - Phase 2 Search Detail: Query + Raw Snippets
    - Phase 2 Extraction: K-Node æå–ç»“æœ
    - Phase 2 Reasoning: Match/Conflict åˆ¤å®šç†ç”±
    """
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
        
        self._initialized = True
        self._case_id: str = ""
        self._logs: Dict[str, Any] = {}
        self._reset_logs()
    
    @classmethod
    def get_instance(cls) -> "TraceLogger":
        """è·å–å•ä¾‹å®ä¾‹"""
        return cls()
    
    def _reset_logs(self):
        """é‡ç½®æ—¥å¿—ç»“æ„"""
        self._logs = {
            "case_id": "",
            "timestamp": "",
            "phase1": {
                "top_candidates": [],
                "initial_diagnosis": "",
                "p_nodes_count": 0
            },
            "phase2": {
                "kgen_searches": [],      # K-Gen æœç´¢è®°å½•
                "kpivot_searches": [],    # K-Pivot æœç´¢è®°å½•
                "extractions": [],        # K-Node æå–è®°å½•
                "reasoning": [],          # Match/Conflict åˆ¤å®šè®°å½•
                "batch_reasoning_raw": "" # ä»…åœ¨è§£æå¤±è´¥æ—¶è®°å½•åŸå§‹å“åº”
            },
            "phase3": {
                "final_diagnosis": "",
                "status": "",
                "reasoning_path": ""
            },
            "naive_scores": {},
            "graph_summary": ""
        }
    
    def start_case(self, case_id: str):
        """
        å¼€å§‹æ–°ç—…ä¾‹çš„è¿½è¸ª
        
        Args:
            case_id: ç—…ä¾‹ ID
        """
        self._reset_logs()
        self._case_id = case_id
        self._logs["case_id"] = case_id
        self._logs["timestamp"] = datetime.now().isoformat()
        print(f"[TraceLogger] Started tracing case: {case_id}")
    
    # ==================== Phase 1 è®°å½• ====================
    
    def log_phase1_result(
        self,
        top_candidates: List[str],
        initial_diagnosis: str,
        p_nodes_count: int
    ):
        """
        è®°å½• Phase 1 ç»“æœ
        
        Args:
            top_candidates: Top-5 å€™é€‰åˆ—è¡¨
            initial_diagnosis: åˆå§‹è¯Šæ–­ ID
            p_nodes_count: P-Nodes æ•°é‡
        """
        self._logs["phase1"]["top_candidates"] = top_candidates
        self._logs["phase1"]["initial_diagnosis"] = initial_diagnosis
        self._logs["phase1"]["p_nodes_count"] = p_nodes_count
    
    # ==================== Phase 2 è®°å½• ====================
    
    def log_kgen_search(
        self,
        disease_name: str,
        disease_id: str,
        query_type: str,
        source: str,
        raw_snippet: str,
        snippet_length: int
    ):
        """
        è®°å½• K-Gen æœç´¢è¯¦æƒ…
        
        Args:
            disease_name: ç–¾ç—…åç§°
            disease_id: ç–¾ç—… ID
            query_type: æœç´¢ç±»å‹ (OpenTargets/Wikipedia/PubMed_Review/PubMed_General)
            source: å®é™…æ¥æº
            raw_snippet: åŸå§‹è¿”å›ç‰‡æ®µ (å‰ 300-500 å­—ç¬¦)
            snippet_length: å®Œæ•´ç‰‡æ®µé•¿åº¦
        """
        search_record = {
            "disease_name": disease_name,
            "disease_id": disease_id,
            "query_type": query_type,
            "source": source,
            "raw_snippet": raw_snippet[:500] if raw_snippet else "",
            "full_length": snippet_length,
            "timestamp": datetime.now().isoformat()
        }
        self._logs["phase2"]["kgen_searches"].append(search_record)
    
    def log_kpivot_search(
        self,
        candidate_a: str,
        candidate_b: str,
        query: str,
        raw_snippets: List[str],
        total_length: int
    ):
        """
        è®°å½• K-Pivot æœç´¢è¯¦æƒ… (ä¸¤ä¸¤å¯¹æ¯”)
        
        Args:
            candidate_a: å€™é€‰ A åç§°
            candidate_b: å€™é€‰ B åç§°
            query: æœç´¢ Query
            raw_snippets: åŸå§‹æ‘˜è¦ç‰‡æ®µåˆ—è¡¨ (æ¯ä¸ªå–å‰ 300 å­—ç¬¦)
            total_length: æ‰€æœ‰æ‘˜è¦æ€»é•¿åº¦
        """
        # æˆªå–æ¯ä¸ª snippet çš„å‰ 300 å­—ç¬¦
        truncated_snippets = [
            s[:300] + "..." if len(s) > 300 else s 
            for s in raw_snippets[:3]  # æœ€å¤šè®°å½• 3 ä¸ª
        ]
        
        search_record = {
            "comparison": f"{candidate_a} vs {candidate_b}",
            "query": query,
            "raw_snippets": truncated_snippets,
            "snippet_count": len(raw_snippets),
            "total_length": total_length,
            "timestamp": datetime.now().isoformat()
        }
        self._logs["phase2"]["kpivot_searches"].append(search_record)
    
    def log_extraction(
        self,
        source_type: str,
        disease_id: str,
        k_nodes_extracted: List[Dict[str, str]],
        edges_created: int
    ):
        """
        è®°å½• K-Node æå–ç»“æœ
        
        Args:
            source_type: æ¥æºç±»å‹ (K-Gen/K-Pivot)
            disease_id: å…³è”çš„ç–¾ç—… ID
            k_nodes_extracted: æå–çš„ K-Nodes åˆ—è¡¨
            edges_created: åˆ›å»ºçš„è¾¹æ•°é‡
        """
        extraction_record = {
            "source_type": source_type,
            "disease_id": disease_id,
            "k_nodes": [
                {
                    "content": k.get("content", "")[:100],
                    "importance": k.get("importance", "Common")
                }
                for k in k_nodes_extracted[:10]  # æœ€å¤šè®°å½• 10 ä¸ª
            ],
            "k_nodes_count": len(k_nodes_extracted),
            "edges_created": edges_created
        }
        self._logs["phase2"]["extractions"].append(extraction_record)
    
    def log_reasoning(
        self,
        k_node_content: str,
        p_node_content: str,
        relation: str,
        reason: str
    ):
        """
        è®°å½• Match/Conflict åˆ¤å®šç†ç”±
        
        Args:
            k_node_content: K-Node å†…å®¹
            p_node_content: P-Node å†…å®¹
            relation: å…³ç³»ç±»å‹ (Match/Conflict/Void)
            reason: åˆ¤å®šç†ç”±
        """
        reasoning_record = {
            "k_node": k_node_content[:100] if k_node_content else "",
            "p_node": p_node_content[:100] if p_node_content else "",
            "relation": relation,
            "reason": reason[:200] if reason else ""
        }
        self._logs["phase2"]["reasoning"].append(reasoning_record)
    
    def log_batch_reasoning_raw(self, raw_response: str, parse_success: bool = False):
        """
        è®°å½• Batch Reasoning çš„åŸå§‹ LLM å“åº”ï¼ˆä»…åœ¨è§£æå¤±è´¥æ—¶è®°å½•ï¼‰
        
        è®¾è®¡åŸåˆ™ï¼šéä¾µå…¥æ€§è¯Šæ–­ï¼Œä»…åœ¨å¤±è´¥æ—¶è§¦å‘
        
        Args:
            raw_response: LLM åŸå§‹å“åº”å†…å®¹
            parse_success: è§£ææ˜¯å¦æˆåŠŸï¼ˆæˆåŠŸæ—¶ä¸è®°å½•ï¼ŒèŠ‚çœç©ºé—´ï¼‰
        """
        if parse_success:
            # è§£ææˆåŠŸæ—¶ä¸è®°å½•åŸå§‹å“åº”
            return
        
        # è§£æå¤±è´¥æ—¶è®°å½•å‰ 1500 å­—ç¬¦ï¼ˆè¶³å¤Ÿçœ‹åˆ°é—®é¢˜ï¼‰
        self._logs["phase2"]["batch_reasoning_raw"] = raw_response[:1500] if raw_response else "(empty response)"
        print(f"[TraceLogger] âš ï¸ Recorded failed Batch Reasoning response ({len(raw_response)} chars)")
    
    # ==================== Phase 3 è®°å½• ====================
    
    def log_phase3_result(
        self,
        final_diagnosis: str,
        status: str,
        reasoning_path: str
    ):
        """
        è®°å½• Phase 3 ç»“æœ
        
        Args:
            final_diagnosis: æœ€ç»ˆè¯Šæ–­
            status: çŠ¶æ€ (Confirm/Overturn/Fallback)
            reasoning_path: æ¨ç†è·¯å¾„
        """
        self._logs["phase3"]["final_diagnosis"] = final_diagnosis
        self._logs["phase3"]["status"] = status
        self._logs["phase3"]["reasoning_path"] = reasoning_path[:500] if reasoning_path else ""
    
    # ==================== è¾…åŠ©è®°å½• ====================
    
    def log_naive_scores(self, scores: Dict[str, float]):
        """è®°å½•ç¡®å®šæ€§è¯„åˆ†"""
        self._logs["naive_scores"] = scores
    
    def log_graph_summary(self, summary: str):
        """è®°å½•å›¾è°±æ‘˜è¦"""
        self._logs["graph_summary"] = summary[:2000] if summary else ""
    
    # ==================== å¯¼å‡º ====================
    
    def export_to_markdown(self, output_dir: str = "output/debug_traces") -> str:
        """
        å¯¼å‡ºä¸º Markdown æ–‡ä»¶
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        filename = f"{self._case_id}_debug.md"
        filepath = os.path.join(output_dir, filename)
        
        # ç”Ÿæˆ Markdown å†…å®¹
        md_content = self._generate_markdown()
        
        # å†™å…¥æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        print(f"[TraceLogger] Exported debug trace to: {filepath}")
        return filepath
    
    def _generate_markdown(self) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼çš„æ—¥å¿—å†…å®¹"""
        lines = []
        
        # æ ‡é¢˜
        lines.append(f"# Debug Trace: {self._logs['case_id']}")
        lines.append(f"\n**Generated:** {self._logs['timestamp']}\n")
        lines.append("---\n")
        
        # Phase 1 æ‘˜è¦
        lines.append("## ğŸ“‹ Phase 1: Initial Diagnosis\n")
        p1 = self._logs["phase1"]
        lines.append(f"- **Top-5 Candidates:** {', '.join(p1['top_candidates'])}")
        lines.append(f"- **Initial Diagnosis:** {p1['initial_diagnosis']}")
        lines.append(f"- **P-Nodes Count:** {p1['p_nodes_count']}\n")
        
        # Phase 2 æœç´¢è¯¦æƒ…
        lines.append("## ğŸ” Phase 2: Knowledge Search Details\n")
        
        # K-Gen æœç´¢
        if self._logs["phase2"]["kgen_searches"]:
            lines.append("### K-Gen Searches (General Knowledge)\n")
            lines.append("| Disease | Source | Snippet Length | Raw Snippet Preview |")
            lines.append("|---------|--------|----------------|---------------------|")
            
            for search in self._logs["phase2"]["kgen_searches"]:
                snippet_preview = search["raw_snippet"][:150].replace("\n", " ").replace("|", "\\|")
                if len(search["raw_snippet"]) > 150:
                    snippet_preview += "..."
                lines.append(
                    f"| **{search['disease_name']}** | {search['source']} | "
                    f"{search['full_length']} chars | {snippet_preview} |"
                )
            lines.append("")
        
        # K-Pivot æœç´¢ (å…³é”®ï¼)
        if self._logs["phase2"]["kpivot_searches"]:
            lines.append("### ğŸ¯ K-Pivot Searches (Differential Diagnosis) - CRITICAL\n")
            
            for i, search in enumerate(self._logs["phase2"]["kpivot_searches"], 1):
                lines.append(f"#### Comparison {i}: {search['comparison']}\n")
                lines.append(f"**Query:** `{search['query']}`\n")
                lines.append(f"**Results:** {search['snippet_count']} abstracts, {search['total_length']} total chars\n")
                
                if search["raw_snippets"]:
                    lines.append("**Raw Snippets Preview:**\n")
                    for j, snippet in enumerate(search["raw_snippets"], 1):
                        lines.append(f"```text\n[Snippet {j}]\n{snippet}\n```\n")
                lines.append("")
        
        # K-Node æå–
        if self._logs["phase2"]["extractions"]:
            lines.append("### ğŸ“¦ K-Node Extractions\n")
            lines.append("| Source Type | Disease ID | K-Nodes | Edges |")
            lines.append("|-------------|------------|---------|-------|")
            
            for ext in self._logs["phase2"]["extractions"]:
                lines.append(
                    f"| {ext['source_type']} | {ext['disease_id']} | "
                    f"{ext['k_nodes_count']} | {ext['edges_created']} |"
                )
            lines.append("")
            
            # è¯¦ç»† K-Nodes åˆ—è¡¨
            lines.append("<details>\n<summary>Click to expand K-Node details</summary>\n")
            for ext in self._logs["phase2"]["extractions"]:
                lines.append(f"\n**{ext['disease_id']}:**")
                for k in ext["k_nodes"]:
                    lines.append(f"- [{k['importance']}] {k['content']}")
            lines.append("\n</details>\n")
        
        # Reasoning è®°å½•
        if self._logs["phase2"]["reasoning"]:
            lines.append("### ğŸ§  Match/Conflict Reasoning\n")
            lines.append("| K-Node | P-Node | Relation | Reason |")
            lines.append("|--------|--------|----------|--------|")
            
            for r in self._logs["phase2"]["reasoning"][:20]:  # æœ€å¤šæ˜¾ç¤º 20 æ¡
                k_content = r["k_node"][:50].replace("|", "\\|")
                p_content = r["p_node"][:50].replace("|", "\\|")
                reason = r["reason"][:100].replace("|", "\\|")
                relation_emoji = {"Match": "âœ…", "Conflict": "âŒ", "Void": "â“"}.get(r["relation"], "")
                lines.append(f"| {k_content} | {p_content} | {relation_emoji} {r['relation']} | {reason} |")
            lines.append("")
        
        # Batch Reasoning åŸå§‹å“åº”ï¼ˆä»…åœ¨è§£æå¤±è´¥æ—¶æ˜¾ç¤ºï¼‰
        batch_raw = self._logs["phase2"].get("batch_reasoning_raw", "")
        if batch_raw:
            lines.append("### âš ï¸ Batch Reasoning Parse Failed - Raw LLM Response\n")
            lines.append("<details>")
            lines.append("<summary>Click to expand raw response (diagnostic info)</summary>\n")
            lines.append("```json")
            # è½¬ä¹‰å¯èƒ½ç ´å Markdown çš„å­—ç¬¦
            safe_raw = batch_raw.replace("```", "'''")
            lines.append(safe_raw)
            lines.append("```")
            lines.append("</details>\n")
        
        # Naive Scores
        if self._logs["naive_scores"]:
            lines.append("## ğŸ“Š Naive Scores (Deterministic)\n")
            lines.append("| Candidate | Score |")
            lines.append("|-----------|-------|")
            
            sorted_scores = sorted(
                self._logs["naive_scores"].items(), 
                key=lambda x: x[1], 
                reverse=True
            )
            for d_id, score in sorted_scores:
                lines.append(f"| {d_id} | {score:.2f} |")
            lines.append("")
        
        # Graph Summary
        if self._logs["graph_summary"]:
            lines.append("## ğŸ“ Graph Summary (Input to Phase 3)\n")
            lines.append("```text")
            lines.append(self._logs["graph_summary"])
            lines.append("```\n")
        
        # Phase 3 ç»“æœ
        lines.append("## âš–ï¸ Phase 3: Final Verdict\n")
        p3 = self._logs["phase3"]
        status_emoji = {"Confirm": "âœ…", "Overturn": "ğŸ”„", "Fallback": "âš ï¸"}.get(p3["status"], "")
        lines.append(f"- **Final Diagnosis:** {p3['final_diagnosis']}")
        lines.append(f"- **Status:** {status_emoji} {p3['status']}")
        lines.append(f"\n**Reasoning Path:**\n```\n{p3['reasoning_path']}\n```\n")
        
        # ç»“æŸ
        lines.append("---")
        lines.append(f"*Generated by TraceLogger at {datetime.now().isoformat()}*")
        
        return "\n".join(lines)
    
    def get_logs(self) -> Dict[str, Any]:
        """è·å–åŸå§‹æ—¥å¿—å­—å…¸ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        return self._logs.copy()

